## RNN & LSTM
## Recurrent Neural Networks (RNN)
- What is RNN?  
  RNN carries previous information and allow them to persist. It use loops in the networks to retain the information.

  <div align="center">
  <img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-rolled.png", width= 100 /><br>
  <strong>Figure 1, RNN with loops</strong>
  </div>

  Network block A, input $x_i$ and output $h_t$, The loop can carry the information from one step to next.

  <div align="center">
  <img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png", width= 500px /><br>
  <strong>Figure 2, An unrolled recurrent neural network</strong>
  </div>

  The chain-like net  is vary suitable for sequence data. It usually used to construct language modeling, speech recognition and video feature extracting..., some RL models using RNN + LSTM to extract the latent information from several continuous video frames as the model inputs. In general, RNN uses loops to merge features of related data and passes these features as hidden states to next step to keep information in the networks. It allows the model to use the previous information to archive the present task, such as inferring the last word for a sentence by language model, understanding the present video frame by previous video frames.  
- Limitation
  If the network-chains is long, the network can't keep initial information. The network is myopia.
<br>

## Long Short Term Memory networks (LSTM)
introduced by [Hochreiter & Schmidhuber](http://www.bioinf.jku.at/publications/older/2604.pdf) 1997 
- What is LSTM ?  
  LSTM is a special kind of RNN, having ability of learning lean-term dependencies. It is exactly designed to overcome the long-term dependency problem.
- Structure
  <div align="center">
  <img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-SimpleRNN.png", width= 300px /><br>
  <strong>Figure 3, The repeating module in a standard RNN contains a single layer</strong>
  </div>
  <div align="center">
  <img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png", width= 300px /><br>
  <strong>Figure 4, The repeating module in an LSTM contains four interacting layers</strong>
  </div>



