<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.55.6" />

<META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">

<link rel="alternate" type="application/rss&#43;xml" href="/docs/index.xml">

<link rel="shortcut icon" href="/assets/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/assets/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/assets/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/assets/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/assets/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/assets/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/assets/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/assets/favicons/android-96x196.png" sizes="96x196">
<link rel="icon" type="image/png" href="/assets/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/assets/favicons/android-192x192.png"sizes="192x192">

<title>Planning and models</title>
<meta property="og:title" content="Planning and models" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://localhost:4000" />
<meta property="og:site_name" content="http://localhost:4000" />

<meta itemprop="name" content="Planning and models">
<meta itemprop="description" content="">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Planning and models"/>
<meta name="twitter:description" content=""/>

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/palette.css">
<script
  src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>
</head>

  

  <body class="td-section">
    <header>
        <nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/">
            <span class="navbar-logo"></span><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149v0 0zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032s-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zM197.0804 232.033c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><path style="fill:#5b7fc0" d="M198.8952 225.1043h122.6266v13.8671H198.8952z"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032s-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zM197.0804 177.6188c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><path style="fill:#d95140" d="M198.8952 170.69h122.6266v13.8671H198.8952z"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zM197.5309 286.4723c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><path style="fill:#56a55c" d="M199.3456 279.5436h122.6266v13.8671H199.3456z"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032-4.13-4.1299-6.4032-9.6186-6.4056-15.4628.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zM197.0804 340.5784c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><path style="fill:#f1bc42" d="M198.8952 333.6497h122.6266v13.8671H198.8952z"/></g></g></svg>
<span class="text-uppercase font-weight-bold">Yukai Wu</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="navbar-nav mt-2 mt-lg-0">
			<li class="nav-item mr-4 mb-2 mb-lg-0">
                            <a class="nav-link" href="https://github.com/wyk2796" target="_blank"><span>GitHub</span></a>
			</li>
			<li class="nav-item mr-4 mb-2 mb-lg-0">
                            <a class="nav-link" href="/about" ><span>About</span></a>
			</li>
		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block">
 <input type="search" class="form-control td-search-input" placeholder="&#xf002 Search this site…" aria-label="Search this site…" autocomplete="off">
        </div>

	<div class="navbar-nav d-none d-lg-block">
            <!-- <div class="gh-source__repository"> -->
    <a class="gh-source" data-gh-source="github" href="https://github.com/wyk2796" title="Go to repository" data-md-state="done">
      <i class="fab fa fa-github fa-2x" style='padding-right:20px; float:left; margin-top:5px'></i>
    </a>
    <a  class="gh-source"   data-gh-source="github"href="https://www.linkedin.com/in/yukau-wu" title="Go to linkedin" data-md-state="done">
      <i class="fab fa-linkedin-in fa-2x" style='padding-right:20px; float:left; margin-top:5px'></i>
    </a>
              <!-- yukai wu/yukai wu -->
              <!-- </div> -->
            <!-- </div> -->
              <!-- <ul class="gh-source__facts">
                <li class="gh-source__fact" id='stars'>
                </li>
                <li id="forks" class="gh-source__fact">
                </li>
              </ul> -->
  </div>

</nav>
<!-- <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
                    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
                            });
  </script>
  <script type="text/javascript"
    src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script> -->
</header>


<script>
$(document).ready(function() {
  var url = "https://api.github.com/search/repositories?q=yukai wu/yukai wu";
  fetch(url, { 
      headers: {"Accept":"application/vnd.github.preview"}
  }).then(function(e) {
    return e.json()
  }).then(function(r) {
     console.log(r.items[0])
     stars = r.items[0]['stargazers_count']
     forks = r.items[0]['forks_count']
     $('#stars').text(stars + " Stars")
     $('#forks').text(forks + " Forks")
  });
});
</script>

    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
          <div id="td-sidebar-menu" class="td-sidebar__inner">  
  <form class="td-sidebar__search d-flex align-items-center">
 <input type="search" class="form-control td-search-input" placeholder="&#xf002 Search this site…" aria-label="Search this site…" autocomplete="off">
    <button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type="button" data-toggle="collapse" data-target="#td-section-nav" aria-controls="td-docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    </button>
  </form>  
  <nav class="collapse td-sidebar-nav pt-2 pl-4" id="td-section-nav">
<ul class="td-sidebar-nav__section pr-md-3">
  <li class="td-sidebar-nav__section-title">
    <a  href="/" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">List</a>
  </li><ul>
    <li class="collapse show" id="list">
        <ul class="td-sidebar-nav__section pr-md-3">
          <li class="td-sidebar-nav__section-title">
            <a href="/news" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">Study Note</a>
          </li>
          <ul><li class="collapse show" id=""></li></ul>
          <li class="td-sidebar-nav__section-title">
            <a href="/about" class="align-left pl-0 pr-2 td-sidebar-link td-sidebar-link__section">About Me</a>
          </li>
          <ul><li class="collapse show" id=""></li></ul>
    </ul>
  </nav>
</div>

          </div>
          <div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
              <div class="td-page-meta ml-2 pb-1 pt-2 mb-0">
                  <a href="https://github.com/wyk2796/edit/master/_posts/2019-05-23-Planning and Models.md" target="_blank"><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a href="https://github.com/wyk2796/issues/new?labels=question&title=Question:&body=Question on: https://github.com/wyk2796/tree/master/_posts/2019-05-23-Planning and Models.md" target="_blank"><i class="fab fa-github fa-fw"></i> Create documentation issue</a>
<a href="https://github.com/wyk2796/issues/new" target="_blank"><i class="fas fa-tasks fa-fw"></i> Create project issue</a>
<!-- this will parse through the header fields and add a button to open
     an issue / ask a question on Github. The editable field should be in
     the post frontend matter, and refer to the label to open the issue for -->

              </div>
              <nav id="TableOfContents"><ul>
              <li><ul id="TOC">
                <!-- Links will be appended here-->
              </ul></li>
              </ul></nav>
          </div>
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            <nav aria-label="breadcrumb" class="d-none d-md-block d-print-none">
	      <ol class="breadcrumb spb-1">
                <li class="breadcrumb-item active" aria-current="page">
	          <a href="/2019/Planning-and-Models/">Planning and models</a>
                </li>
	      </ol>
           </nav>
           <div class="td-content">
	      <h1 style="margin-bottom:0px">Planning and models</h1>

<span class="post-date" style="font-style: italic;">May 23, 2019</span>
<h3 id="1-model-based-and-model-free-rl">1. Model-Based and Model-Free RL</h3>
<ul>
  <li>Model-Free RL
    <ul>
      <li>No model</li>
      <li><strong>Learn</strong> value function (and/or policy) from experience</li>
    </ul>
  </li>
  <li>Model-Based RL
    <ul>
      <li><strong>Learn</strong> a model from experience OR be given a model</li>
      <li><strong>Plan</strong> value function (and/or policy) from model</li>
    </ul>
  </li>
</ul>

<!--more-->

<hr />
<h3 id="2-what-is-a-model">2. What is a Model?</h3>
<ul>
  <li>A model $\mathcal{M}<em>\eta$ is a representation of MDP $\langle \mathcal{S, A}, \hat{p}</em>\eta \rangle$</li>
  <li>For now, we will assume the states and actions are the same as in the real problem</li>
  <li>
    <p>The model <strong>approximates</strong> the state transitions and rewards $\hat{p}_\eta\approx p$<br />
<script type="math/tex">R_{t+1}, S_{t+1} \sim \hat{p}_\eta (r, s'|S_t,A_t)</script><br />
(Note there is not probability distribution function)</p>
  </li>
  <li>Optionally, we could model rewards and state dynamics separately</li>
</ul>

<hr />
<h3 id="3-model-learning">3. Model Learning</h3>
<ul>
  <li>Goal: <strong>estimate</strong> model $\mathcal{M}_\eta$ from experienve ${S_1, A_1, R_2,\ldots,S_T}$</li>
  <li>This is a supervised learning problem<br />
<script type="math/tex">% <![CDATA[
\begin{aligned}
S_1,A_1 &\rightarrow R_2, S_2 \\
&\vdots \\
S_{T-1},A_{T-1} &\rightarrow R_{T}, S_{T}
\end{aligned} %]]></script></li>
  <li>Learn a function $f(s,a) = r,s’$</li>
  <li>Pick loss function (e.g. mean-squared error), and find parameters $\eta$ that minimise empirical loss</li>
  <li>This would give an expectation model</li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>If $f(s,a)=r,s’$, then we would hope $s’\approx \mathbb{E}[S_{t+1}</td>
          <td>s=S_t,a=A_t]$</td>
        </tr>
      </tbody>
    </table>
  </li>
</ul>

<hr />
<h3 id="4-stochastic-model">4. Stochastic Model</h3>

<ul>
  <li>We may not want to assume everything is linear</li>
  <li>Then expected states may not be roght — they may not correspond to actual states, and iterating the model may do weird things.</li>
  <li>Alternative: <strong>stochastic models</strong> (also know as <strong>generative models</strong>) 
<script type="math/tex">\hat{R}_{t+1}, \hat{S}_{t+1} = \hat{p}(S_t, A_t,\omega)</script>
where $\omega$ is a noise term</li>
  <li>Stochastic models can be chained, even if the model is non-linear.</li>
  <li>But they do add not noise</li>
</ul>

<hr />
<h3 id="5-exmples-of-models">5. Exmples of Models</h3>
<ul>
  <li>Table Looking Model</li>
  <li>Linear Expectation Model</li>
  <li>Linear Gaussian Model</li>
  <li>Deep Neural Network Model</li>
  <li>……</li>
</ul>

<h4 id="51-table-lookup-model">5.1 Table Lookup Model</h4>
<ul>
  <li>Model is an explicit MDP</li>
  <li>Count visits $N(s,a)$ to each state action pair<br />
<script type="math/tex">% <![CDATA[
\begin{aligned}
\hat{p}_t(s'|s,a) &= \frac{1}{N(s,a)}\sum_{k=0}^{t-1}I(S_k=s,A_k=a,S_{k+1}=s') \\
\mathbb{\hat{p}_t}[R_{t+1}|S_t=s,A_t=a] &= \frac{1}{N(s,a)}\sum_{k=0}^{t-1}I(S_k=s,A_k=a)R_{k+1}
\end{aligned} %]]></script></li>
  <li>Alternatively, use non-parameteric ‘replay’
    <ul>
      <li>At each time-step t, record experience tuple $\langle S_t,A_t,R_{t+1},S_{t+1} \rangle$</li>
      <li>To sample model, randomly pick tuple matching $\langle s,a,\cdot,\cdot\rangle$</li>
    </ul>
  </li>
</ul>

<hr />
<h3 id="6-planing-with-a-model">6. Planing with a Model</h3>
<ul>
  <li>Given a model $\hat{p}_\eta$</li>
  <li>Solve the MDP $\langle \mathcal{S,A},\hat{p}_\eta \rangle$</li>
  <li>Using favourite planning algorithm
    <ul>
      <li>Value iteration</li>
      <li>Policy iteration</li>
      <li>Tree search</li>
      <li>……</li>
    </ul>
  </li>
</ul>

<h4 id="61-sample-based-planning">6.1 Sample-Based Planning</h4>
<ul>
  <li>A simple but powerful approach to planning</li>
  <li>Use the model <strong>only</strong> to generate sampler</li>
  <li><strong>Sample</strong> experience from model<br />
<script type="math/tex">S,R \sim \hat{p}_\eta(\cdot|s,a)</script></li>
  <li>Apply <strong>model-free</strong> RL to sample, e.g.:
    <ul>
      <li>Monte-Carlo control</li>
      <li>Sarsa</li>
      <li>Q-learning</li>
    </ul>
  </li>
</ul>

<hr />
<h3 id="7-conventional-model-based-and-model-free-metheds">7. Conventional model-based and model-free metheds</h3>

<p>Traditional RL algorithms did not explicitly store their experiences, and were often placed into one of two groups.</p>
<ul>
  <li><strong>Model-free</strong> methods update the value function and/or policy and do not have explicit dynamics models.</li>
  <li><strong>Models-based</strong> methods update the transition and reward models, and compute a value function or policy from the model.</li>
</ul>

<hr />
<h3 id="8-using-experience-in-the-place-of-model">8. Using experience in the place of model</h3>
<p>Recall prioritized sweeping from tabular dynamic programming</p>
<ul>
  <li>Update the value function of the states with the largest magnitude Bellman errors using a priority queue.
A related idea is prioritized experience replay (Schaul et al, 2015) which works from experience for general function approximation.</li>
  <li>The experience replay buffer maintain a priority for each transition, with the priority given by the magnitude of the Bellman error.</li>
  <li>Minibatches are sampled using this priority to quickly reduce errors.</li>
  <li>Weighted importance sampling corrects for bias from non-uniform sampling</li>
</ul>

<hr />
<h3 id="9-limits-of-planning-with-an-inaccurate-model">9. Limits of Planning with an Inaccurate Model</h3>
<ul>
  <li>Given an imperfect model $\hat{p}_\eta \neq p$</li>
  <li>Performance is limited to optimal policy for approximate MDP $\langle \mathcal{M,A,\hat{p}_\eta}\rangle$</li>
  <li>Model-based RL is only as good as the estimated model</li>
  <li>When the model is inaccurate, planning process will compute a suboptimal policy (not covered in these slides)
    <ul>
      <li>Approach 1: when model is wrong, use model-free RL</li>
      <li>Approach 2: reson explicitly about model uncertainty over $\eta$ (e.g. Bayesian methon)</li>
      <li>Approach 3: Combine model-based and model-free methods in a safe way.</li>
    </ul>
  </li>
</ul>

<hr />
<h3 id="10-real-and-simulated-experience">10. Real and Simulated Experience</h3>
<p>We consider two sources of experience
Real experience Sampled from environment (true MDP)<br />
<script type="math/tex">r,s'\sim p</script><br />
Sumulated experience Sampled from model (approximate MDP)<br />
<script type="math/tex">r,s' \sim \hat{p}_\eta</script></p>

<hr />
<h3 id="11-intergrating-learning-and-planning">11. Intergrating Learning and Planning</h3>
<ul>
  <li>Model-Free RL
    <ul>
      <li>No model</li>
      <li><strong>Learn</strong> value function (and/or policy) from real experience</li>
    </ul>
  </li>
  <li>Model-Based RL (using Sample-Based Planning)
    <ul>
      <li>Learn a model from real experience</li>
      <li><strong>Plan</strong> value function (and/or policy) from simulated experience</li>
    </ul>
  </li>
  <li>Dyna
    <ul>
      <li>Learn a model from real experience</li>
      <li><strong>Learn AND plan</strong> value function (and/or policy) from real and simulated experience</li>
      <li>Treat real and sumulated esperience equivalently. Conceptually, the update from learning or planning are not distinguished.</li>
    </ul>
  </li>
</ul>

<h4 id="111-dyna-q-algorithm">11.1 Dyna-Q Algorithm</h4>

<blockquote>
  <script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
& \text{Initialize}\space Q(s,a)\space \text{and Model}(s,a)\quad \text{for all}\space s\in\mathcal{A}(s) \\
& \text{Do forever:} \\
& \qquad (a) \quad s \leftarrow \text{current (nonterminal) state} \\
& \qquad (b)\quad a \leftarrow \epsilon\text{-greedy}(s,Q) \\
& \qquad (c) \quad \text{Execute action}\space a\text{; observe resultant state, }s'\text{, and reward, }r\\
& \qquad (d)\quad Q(s,a)\leftarrow Q(s,a)+\alpha[r + \gamma\max_{a'}Q(s',a')-Q(s,a)]\\
& \qquad (e)\quad Model(s,a) \leftarrow s',r \quad\text{(assuming deterministic environment)}\\
& \qquad (f)\quad \text{Repeat}\space N \space \text{times:} \\
& \qquad\qquad s \leftarrow \text{random previously observed state} \\
& \qquad\qquad a\leftarrow \text{random action previously taken in}\space s \\
& \qquad\qquad s',r \leftarrow Model(s,a) \\
& \qquad\qquad Q(s,a)\leftarrow Q(s,a) + \alpha[r+\gamma\max_{a'}Q(s',a')-Q(s,a)]
\end{aligned} %]]></script>
</blockquote>

<h3 id="112-dyna-with-function-approximation">11.2 Dyna with Function Approximation</h3>
<ul>
  <li>How can an agent plan when the actual environmental states are not know?</li>
  <li>Can directly approximate probability distributions of the transitions and the rewards.</li>
  <li>Probability distribution models in high dimensional feature spaces are computationally expensive and often inaccurate!</li>
</ul>

<hr />
<h3 id="12-planning-for-action-selection">12. Planning for Action Selection</h3>
<ul>
  <li>We considered the case where planning is used to improve a global value function</li>
  <li>Now consider planning for the near future, to select the next action</li>
  <li>The distribution of states that may be encounted from <strong>now</strong> can diff from the distribution of states encountered from a starting state</li>
  <li>The agent may be able to make a more accurate local value function (for the states that will be encountered soon) than the global value function</li>
</ul>

<h4 id="121-forward-search">12.1 Forward Search</h4>
<ul>
  <li><strong>Forward search</strong> algorithms select the best action by <strong>look ahead</strong></li>
  <li>They build a search tree with the current state $s_t$ at the root</li>
  <li>
    <p>Using a <strong>model</strong> of the MDP to look ahead
<img src="https://i.loli.net/2019/12/24/QkTADdw2EPx4zyG.png" alt="tree" /></p>
  </li>
  <li>No need to solve whole MDP, just sub-MDP starting from <strong>now</strong></li>
</ul>

<h4 id="122-simulation-based-search">12.2 Simulation-Based Search</h4>
<ul>
  <li><strong>Forward</strong> search paradigm using sample-based planning</li>
  <li><strong>Simulate</strong> episodes of experience from <strong>now</strong> with the model</li>
  <li>
    <p>Apply <strong>model-free</strong> RL to simulated episodes<br />
<img src="https://i.loli.net/2019/12/24/JmliqxjnY7TB5fI.png" alt="Search Path" /></p>
  </li>
  <li>Simulate episode of experience from <strong>now</strong> with the model<br />
<script type="math/tex">\{S_t^k, A_t^k,R_{t+1}^k,\ldots,S_T^k\}_{k=1}^K \sim \hat{p}_\eta</script></li>
  <li>Apply <strong>model-free</strong> RL to sumulated episodes
    <ul>
      <li>Monte-carlo control $\rightarrow$ Monte-Carlo search</li>
      <li>Sarsa $\rightarrow$ TD search</li>
    </ul>
  </li>
</ul>

<h4 id="123-search-tree-vs-value-function-approximation">12.3 Search tree vs. value function approximation</h4>
<ul>
  <li>Search tree is a table lookup approach</li>
  <li>Based on a partial instantiation of the table</li>
  <li>For model-free reinforcement learning, table lookup is naive
    <ul>
      <li>Can’t store value for all states</li>
      <li>Doesn’t generalise between similar states</li>
    </ul>
  </li>
  <li>For simulation-based search, table lookup is less naive
    <ul>
      <li>Search tree stores value for easily reachable states</li>
      <li>In huge search spaces, value function approximation is helpful</li>
    </ul>
  </li>
</ul>

<h3 id="13-monte-carlo-simulation">13. Monte-Carlo Simulation</h3>
<ul>
  <li>Given a parameterized model $\mathcal{M}_\eta$ and a <strong>simulation policy</strong> $\pi$</li>
  <li>Simulate $K$ episodes from current state $S_t$<br />
<script type="math/tex">\{S_t^k=S_t,A_t^k,R_{t+1}^k,S_{t+1}^k,\ldots,S_t^k\}_{k=1}^K \sim \hat{p}_\eta, \pi</script></li>
  <li>Evaluate state by mean return (<strong>Monte-Carlo evaluaiton</strong>)<br />
<script type="math/tex">v(\color{red}{S_t})=\frac{1}{K}\sum_{k=1}^K G_t^k \rightsquigarrow v_\pi(S_t)</script></li>
</ul>

<h4 id="131-simple-monte-carlo-search">13.1 Simple Monte-Carlo Search</h4>
<ul>
  <li>Given a model $\mathcal{M}_\eta$ and a policy $\pi$</li>
  <li>For each action $a \in \mathcal{A}$
    <ul>
      <li>Simulate $K$ episodes from current (real) state $s$<br />
<script type="math/tex">\{S_t^k=s,A_t^k=a,R_{t+1}^k,S_{t+1}^k,A_{t+1}^k,\ldots,S_t^k\}_{k=1}^K \sim \mathcal{M}_v,\pi</script></li>
      <li>Evaluate actions by mean return (Monto-Carlo evaluation)<br />
<script type="math/tex">q(\color{red}{s,a})=\frac{1}{K}\sum_{k=1}^K G_t^k \rightsquigarrow q_\pi(S_t)</script></li>
      <li>Select current (real) action with maximum value<br />
<script type="math/tex">A_t=\mathop{\text{argmax}}\limits_{a\in\mathcal{A}}q(S_t,a)</script></li>
    </ul>
  </li>
</ul>

<h4 id="132-monte-carlo-tree-search-evaluation">13.2 Monte-Carlo Tree Search (Evaluation)</h4>
<ul>
  <li>Given a model $\mathcal{M}_\eta$</li>
  <li>Simulate $K$ episodes from current state $S_t$ using current simulation policy $\pi$<br />
<script type="math/tex">\{\color{red}{S_t^k=S_t},A_t^k,R_{t+1}^k,S_{T+1}^k,\ldots,S_t^k\}_{k=1}^K \sim \mathcal{M}_v,\pi</script></li>
  <li>Build a search tree containing visited states and actions</li>
  <li><strong>Evaluate</strong> states $q(s,a)$ by mean return of eqisodes from $s,a$<br />
<script type="math/tex">q(s,a)=\frac{1}{N(s,a)}\sum_{k=1}^K\sum_{u=t}^T1(S_u^k,A_u^k=s,a)(G_u^k \rightsquigarrow q_\pi(s,a))</script></li>
  <li>After searching, select current (real) action with maximum value in search tree<br />
<script type="math/tex">a_t=\mathop{\text{argmax}}\limits_{a\in\mathcal{A}}q(S_t,a)</script></li>
</ul>

<h4 id="monte-carlo-tree-search-simulation">Monte-Carlo Tree Search (Simulation)</h4>
<ul>
  <li>In MCTS, the simulation policy $\pi$ <strong>improves</strong></li>
  <li>The simulation policy $\pi$ has two phases (in-tree, out-of-tree)
    <ul>
      <li><strong>Tree policy</strong> (improves): pick action from $q(s,a)$ (e.g. $\epsilon$-greedy($q(s,a)$))</li>
      <li><strong>Rollout policy</strong> (fixed): e.g., pick actions randomly</li>
    </ul>
  </li>
  <li>Repeat (for each simulated episode)
    <ul>
      <li><strong>Select</strong> actions in tree according to tree policy</li>
      <li><strong>Expand</strong> search tree by one node</li>
      <li><strong>Rollout</strong> to termination with default policy</li>
      <li><strong>Update</strong> action-values $q(s,a)$ in the tree</li>
    </ul>
  </li>
  <li>Output best action when simulation time runs out.</li>
  <li>With some asumptions, converges to the optimal values, $q(s,a)\Rightarrow q_*(s,a)$</li>
</ul>


<script
  src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>

<script>
$(document).ready(function() {

    var toc = $('#TOC');

    // Select each header
    sections = $('.td-content h1');
        $.each(sections, function(idx, v) {
            section = $(v);
            var div_id = $(section).attr('id');
            var div_text = section.text().split('¶')[0];
            var parent = $("#" + div_id)
            var content = '<li id="link_' + div_id + '" class="md-nav__item"><a class="md-nav__link" href="#' + div_id + '" title="' + div_text +'">' + div_text +'</a></li>';
            $(toc).append(content);

            // Add section code to subnavigation
            var children = $('<nav class="md-nav"><ul class="md-nav__list"></nav></ul>')
            var contenders = $("#" + div_id).nextUntil("h1");
            $.each(contenders, function(idx, contender){
               if($(contender).is('h2') || $(contender).is('h3')) {
                   var contender_id = $(contender).attr('id');
                   var contender_text = $(contender).text().split('¶')[0];
                   var content = '<li class="md-nav__item"><a class="md-nav__link" href="#' + contender_id + '" title="' + contender_text +'">' + contender_text +'</a></li>';
                   children.append(content);
                }
             })
             $("#link_" + div_id).append(children);
        });
    });
</script>

<script>
var headers = ["h1", "h2", "h3", "h4"]
var colors = ["red", "orange", "green", "blue"]

$.each(headers, function(i, header){
    var color = colors[i];
    $(header).each(function () {
        var href=$(this).attr("id");
        $(this).append('<a class="headerlink" style="color:' + color + '" href="#' + href + '" title="Permanent link">¶</a>')
    });
})
</script>

<script>
$('h1').first().append('<div></div>')</script>

	
              
              <!-- <br/>

 -->
           </div>
          </main>
        </div>
      </div>
      <footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        

</div>
<div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="" aria-label="GitHub" data-original-title="GitHub">
    <a class="text-white" target="_blank" href="https://github.com/wyk2796">
      <i class="fab fa-github"></i>
    </a>
  </li>
</ul>
</div>
<div class="col-12 col-sm-4 text-center py-2 order-sm-2">
  <small class="text-white">© 2019 Yukai Wu All Rights Reserved</small>
  
  <p class="mt-2"><a href="/about/">About Docsy</a></p>	
      </div>
    </div>
  </div>
</footer>

    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
<script src="/assets/js/main.js"></script>

  </body>
  
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">

  <!-- The loading of KaTeX is deferred to speed up page rendering -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>

  <!-- To automatically render math in text elements, include the auto-render extension: -->
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
      onload="renderMathInElement(document.body);"></script>  
</html>
