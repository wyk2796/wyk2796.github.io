<!DOCTYPE html>
<html lang="en" class="no-js">
  <head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.55.6" />

<META NAME="ROBOTS" CONTENT="INDEX, FOLLOW">

<link rel="alternate" type="application/rss&#43;xml" href="/docs/index.xml">

<link rel="shortcut icon" href="/assets/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/assets/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/assets/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/assets/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/assets/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/assets/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/assets/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/assets/favicons/android-96x196.png" sizes="96x196">
<link rel="icon" type="image/png" href="/assets/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/assets/favicons/android-192x192.png"sizes="192x192">

<title>Search</title>
<meta property="og:title" content="Search" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="http://localhost:4000" />
<meta property="og:site_name" content="http://localhost:4000" />

<meta itemprop="name" content="Search">
<meta itemprop="description" content="">

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Search"/>
<meta name="twitter:description" content=""/>

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="stylesheet" href="/assets/css/palette.css">
<script
  src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>
</head>

  

  <body class="td-section">
    <header>
        <nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
        <a class="navbar-brand" href="/">
            <span class="navbar-logo"></span><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149v0 0zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032s-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zM197.0804 232.033c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zM197.0839 232.0372c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><path style="fill:#5b7fc0" d="M198.8952 225.1043h122.6266v13.8671H198.8952z"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032s-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zM197.0804 177.6188c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zM197.0839 177.623c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><path style="fill:#d95140" d="M198.8952 170.69h122.6266v13.8671H198.8952z"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zM197.5309 286.4723c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zM197.5344 286.4765c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><path style="fill:#56a55c" d="M199.3456 279.5436h122.6266v13.8671H199.3456z"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.328-2.2733-15.458-6.4032-4.13-4.1299-6.4032-9.6186-6.4056-15.4628.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zM197.0804 340.5784c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zM197.0839 340.5826c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><path style="fill:#f1bc42" d="M198.8952 333.6497h122.6266v13.8671H198.8952z"/></g></g></svg>
<span class="text-uppercase font-weight-bold">Yukai Wu</span>
	</a>
	<div class="td-navbar-nav-scroll ml-md-auto" id="main_navbar">
		<ul class="navbar-nav mt-2 mt-lg-0">
			<li class="nav-item mr-4 mb-2 mb-lg-0">
                            <a class="nav-link" href="/about" ><span>About</span></a>
			</li>
			<li class="nav-item mr-4 mb-2 mb-lg-0">
                            <a class="nav-link" href="/about" ><span>Documentation</span></a>
			</li>
		</ul>
	</div>
	<div class="navbar-nav d-none d-lg-block">
 <input type="search" class="form-control td-search-input" placeholder="&#xf002 Search this site…" aria-label="Search this site…" autocomplete="off">
        </div>

	<div class="navbar-nav d-none d-lg-block">
          <a class="gh-source" data-gh-source="github" href="" title="Go to repository" data-md-state="done">
          <div class="gh-source__repository">
            <i class="fab fa fa-github fa-2x" style='padding-right:20px; float:left; margin-top:5px'></i>
            yukai wu/yukai wu
          <ul class="gh-source__facts"><li class="gh-source__fact" id='stars'></li><li id="forks" class="gh-source__fact"></li></ul></div></a>
        </div>
      </div>


</nav>
</header>

<script>
$(document).ready(function() {
  var url = "https://api.github.com/search/repositories?q=yukai wu/yukai wu";
  fetch(url, { 
      headers: {"Accept":"application/vnd.github.preview"}
  }).then(function(e) {
    return e.json()
  }).then(function(r) {
     console.log(r.items[0])
     stars = r.items[0]['stargazers_count']
     forks = r.items[0]['forks_count']
     $('#stars').text(stars + " Stars")
     $('#forks').text(forks + " Forks")
  });
});
</script>

    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
          <div id="td-sidebar-menu" class="td-sidebar__inner">  
  <form class="td-sidebar__search d-flex align-items-center">
 <input type="search" class="form-control td-search-input" placeholder="&#xf002 Search this site…" aria-label="Search this site…" autocomplete="off">
    <button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type="button" data-toggle="collapse" data-target="#td-section-nav" aria-controls="td-docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    </button>
  </form>  
  <nav class="collapse td-sidebar-nav pt-2 pl-4" id="td-section-nav">
<ul class="td-sidebar-nav__section pr-md-3">
  <li class="td-sidebar-nav__section-title">
    <a  href="/about" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">About Me</a>
  </li><ul class="td-sidebar-nav__section pr-md-3">
  <li class="td-sidebar-nav__section-title">
    <a  href="/news" class="align-left pl-0 pr-2 active td-sidebar-link td-sidebar-link__section">Blogs</a>
  </li>
  </nav>
</div>

          </div>
          <div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
              <div class="td-page-meta ml-2 pb-1 pt-2 mb-0">
                  <a href="/edit/master/pages/search.html" target="_blank"><i class="fa fa-edit fa-fw"></i> Edit this page</a>
<a href="/issues/new?labels=question&title=Question:&body=Question on: /tree/master/pages/search.html" target="_blank"><i class="fab fa-github fa-fw"></i> Create documentation issue</a>
<a href="/issues/new" target="_blank"><i class="fas fa-tasks fa-fw"></i> Create project issue</a>
<!-- this will parse through the header fields and add a button to open
     an issue / ask a question on Github. The editable field should be in
     the post frontend matter, and refer to the label to open the issue for -->

              </div>
              <nav id="TableOfContents"><ul>
              <li><ul id="TOC">
                <!-- Links will be appended here-->
              </ul></li>
              </ul></nav>
          </div>
          <main class="col-12 col-md-9 col-xl-8 pl-md-5" role="main">
            <nav aria-label="breadcrumb" class="d-none d-md-block d-print-none">
	      <ol class="breadcrumb spb-1">
                <li class="breadcrumb-item active" aria-current="page">
	          <a href="/search/">Search</a>
                </li>
	      </ol>
           </nav>
           <div class="td-content">
	      <input class="form-control td-search-input" type="search" name="q" id="search-input" placeholder="&#xf002 Search this site…"  style="margin-top:5px" autofocus>
<i style="color:white; margin-right:8px; margin-left:5px" class="fa fa-search"></i>

<p><span id="search-process">Loading</span> results <span id="search-query-container" style="display: none;">for "<strong id="search-query"></strong>"</span></p>

<ul id="search-results"></ul>

<script>
	window.data = {
		
				
					
					
					"docs-example-page": {
						"id": "docs-example-page",
						"title": "A Nested Page",
						"categories": "",
						"url": " /docs/example-page",
						"content": "A Nested Page\n\nThis is an example of a page that doesn’t have a permalink defined, and\nis not included in the table of contents (_data/toc.yml). This means\nthat it will render based on it’s path. Since it’s in docs/example-page.md,\nthe url will be docs/example-page/.\n\nLink to a subfolder\n\nNow let’s say we want to link to a subfolder, specifically with this\nsetup:\n\ndocs/\n  example-page.md  (-- we are here\n  subfolder/\n     example-page.md  (-- we want to link here\n\n\nYou can provide the relative path to the file, like subfolder/example-page.md\nand Jekyll will handle parsing it. For example:\n\n\n  here is that link\n\n\nAnd here\n is the same link, \nbut generated with the include statement:\n\n{% include doc.html name=\"here\" path=\"subfolder/example-page\" %}"
					}
					
				
		
				
					,
					
					"docs-extras-example-quiz": {
						"id": "docs-extras-example-quiz",
						"title": "Quiz",
						"categories": "",
						"url": " /docs/extras/example-quiz",
						"content": "Quizzes\n\nAs of version 0.0.12, mkdocs-jekyll has support for basic quizzes! These are\nintended to help educate your users about the content of your documentation.\nFor a quiz, you can add a new file to the folder _data/quizzes, and write a \nquestions file based on the format shown in _data/quizzes/example-quiz.yml.\nHere is a simple example of a multiple choice question (which can also serve as \nTrue/False):\n\ntitle: This is the Quiz Title\nrandomized: false\nquestions:\n\n - type: \"multiple-choice\"\n   question: \"True or False, Pittsburgh is West of Philadelphia\"\n   items:\n    - choice: True\n      correct: true\n    - choice: False\n      correct: false\n   followup: | \n      The answer is True! Pittsburgh is 304.9 miles West of \n      Philadelphia, or approximately a car ride of \n      4 hours and 52 minutes. Buckle up!\n\n\nThe quiz is rendered with a “Show Answer” button below each question, and when\nthe user clicks it, any questions that are flagged with correct: true will be \nbolded, and if a followup section is included, it will be displayed.\nSee the live example at the end of this page.\n\nOptions\n\nTitle\n\nIf you include a title, it will be rendered at the top of the quiz. This is\noptional - you can leave it out and add it before the include on the page.\n\nRandom\n\nIf you want your questions to be presented randomly, just add randomized: true\nto the data.\n\nExample Quiz\n\nIf I want to include the quiz located at _data/quizzes/example-quiz.yml, I \ncan do so like this:\n\n{% include quiz.html file='example-quiz' %}\n\n\nThe rendered quiz is shown here:\n\nThis is the Quiz Title\n\nWhat is your favorite color?\n1. Red2. Blue3. Green\n\nShow Answer\nThere is no correct answer to asking your favorite color! All choices would be good.\n\n\nTrue or False, Pittsburgh is West of Philadelphia\n1. true2. false\n\nShow Answer\nThe answer is True! Pittsburgh is 304.9 miles West of Philadelphia, or approximately \na car ride of 4 hours and 52 minutes. Buckle up!"
					}
					
				
		
				
					,
					
					"docs-extras-index": {
						"id": "docs-extras-index",
						"title": "Extras",
						"categories": "",
						"url": " /docs/extras/index",
						"content": "Extras\n\nExtras include other integrations that aren’t relevant to style or customization,\nbut can further enhance your documentation pages. Currently, we have support\nfor adding interactive quizzes.\n\n\n  Quizzes\n\n\nWould you like to see another question type, or another kind of extra? Please\n[open an issue])(/issues/new)."
					}
					
				
		
				
					,
					
					"docs-getting-started": {
						"id": "docs-getting-started",
						"title": "Getting Started",
						"categories": "",
						"url": " /docs/getting-started",
						"content": "Getting Started\n\nFeatures\n\nUser Interaction\n\nOn the right side of any page, you’ll notice links to edit the page, or\nopen an issue. This ensures that any time you have a question or want to \nsuggest or request a change, you can do so immediately and link directly\nto the section of interest. The sections on the page also have permalinks so\nyou can link directly to them.\n\nSearch\n\nThe entire site, including posts and documentation, is indexed and then available\nfor search at the top or side of the page. Give it a try! The content is rendered\ninto window data that is used by lunr.js to generate the search results.\nIf you want to exclude any file from search, add this to its front end matter:\n\n---\nlayout: null\nexcluded_in_search: true\n---\n\n\nThe example above is for a javascript file in the assets folder that is used as a template,\nbut should not be included in search.\n\nExternal Search\n\nIf you have an external site with a search GET endpoint (meaning one that ends\nin ?q=&lt;term&gt;, then you can automatically link page tags to search this endpoint.\nFor example, on an HPC site I’d want a tag like “mpi” to do a search on \nhttp://ask.cyberinfrastructure.org for mpi.\nSee the tags section below for how to configure this.\n\nDocumentation\n\nDocumentation pages should be written in the docs folder of the repository,\nand you are allowed to use whatever level of nesting (subfolders) that \nworks for you! It’s a Jekyll collection, which means that you\ncan add other content (images, scripts) and it will be included for linking to.\n\nOrganization\n\nThe url that will render is based on the path. For example, if we had the following structure:\n\ndocs/\n  getting-started.md\n  clusters/\n     sherlock/\n         getting-started.md\n\n\nThe first page (akin to the one you are reading) would render at it’s path,\n/docs/getting-started/.\n\nLinking\n\nFrom that page, we could provide the\ndirect path in markdown to any subfolder to link to it, such as the second\ngetting started page for sherlock:\n\n[example](clusters/sherlock/getting-started.md)\n\n\nHere is an example link to a relative path of a file (example-page.md)\nin the same directory, and from that page you can test linking to a subfoldr.\nIn the case of not having a subfolder, we could write the link out directly:\n\n[example]({{ site.baseurl }}/docs/clusters/sherlock/getting-started.md)\n\n\nor just put the relative path:\n\n[Here](example-page)\n\n\nor better, there is a shortand trick! We can use the provided “includes” \ntemplate to do the same based on the path to create a link:\n\n{% include doc.html name=\"Sherlock Cluster\" path=\"clusters/sherlock/getting-started\" %}\n\nThe path should be relative to the docs folder.\n\nPages\n\nThe pages folder uses the same page layout, but is not part of the docs collection.\nThe two are provided to create a distinction between website pages (e.g., about,\nfeed.xml) and documentation pages.\n\nNavigation\n\nWhether you place your page under “pages” or “docs,” for those pages that you want added to the navigation, \nyou should add them to _data/toc.yml. If you’ve defined a permalink in the\nfront end matter, you can use that (e.g., “About” below). If you haven’t and\nwant to link to docs, the url is the path starting with the docs folder.\nHere is an example (currently the active example):\n\n- title: Documentation\n  url: docs\n  links:\n    - title: \"Getting Started\"\n      url: \"docs/getting-started\"\n      children:\n        - title: Features\n          url: \"docs/getting-started#getting-started\"\n        - title: Development\n          url: \"docs/getting-started#development\"\n        - title: Customization\n          url: \"docs/getting-started#customization\"\n    - title: \"Extras\"\n      url: \"docs/extras\"\n      children:\n        - title: Quizzes\n          url: \"docs/extras/example-quiz\"\n    - title: \"About\"\n      url: \"about\"\n    - title: \"News\"\n      url: \"news\n\n\nIf you want to add an external url for a parent or child, do this:\n\n  - title: GitHub Repository\n    external_url: https://www.github.com/vsoch/mkdocs-jekyll\n\n\nNews Posts\n\nIt might be the case that your site or group has news items that would\nwarrent sharing with the community, and should be available as a feed.\nFor this reason, you can write traditional posts in the _posts\nfolder that will parse into the site feed\nThe bottom of the page links the user to a post archive, where posts are organized\naccording to the year.\n\nButtons\n\nButtons come in a nice array of colors. Here is the code for a basic example,\nand you’d want to vary the .btn-&lt;tag&gt; to get different classes.\n\n&lt;button class=\"btn btn-success\"&gt;.btn-success&lt;/button&gt;\n\n\n.btn-success\n.btn-info\n.btn-secondary\n.btn-primary\n.btn-danger\n.btn-warning\n\nBadges\n\nFor news post items, it’s nice to be able to tag it with something that indicates\na status, such as “warning” or “alert.” For this reason, you can add badges to\nthe front end matter of any post page, and they will render colored by a type,\nwith the tag of your choice. For example, here is an example header for\na post:\n\n---\ntitle:  \"Two Thousand Nineteen\"\ndate:   2019-06-28 18:52:21\ncategories: jekyll update\nbadges:\n - type: warning\n   tag: warning-badge\n - type: danger\n   tag: danger-badge\n---\n\n\nAnd here is the post preview with the rendered badges that it produces:\n\nwarning-badge\ndanger-badge\n\nAnd the other badges that you can define include success, info, secondary,\nand primary.\n\nsuccess-badge\ninfo-badge\nsecondary-badge\nprimary-badge\n\nAlerts\n\n\nWhat is an alert?\nAn alert is a box that can stand out to indicate important information. You can choose from levels success, warning, danger, info, and primary. This example is an info box, and the code for another might look like this:\n\n\n{% include alert.html type=\"info\" title=\"Here is another!\" %}\n\n\nJust for fun, here are all the types:\n\n\nwarning\nThis is a warning\n\n\n\ndanger\nThis alerts danger!\n\n\n\nsuccess\nThis alerts success\n\n\n\ninfo\nThis is useful information.\n\n\n\nprimary\nThis is a primary alert\n\n\n\nsecondary\nThis is a secondary alert\n\n\nQuotes\n\nYou can include block quotes to emphasize text.\n\n\n  Here is an example. Isn’t this much more prominent to the user?\n\n\nDevelopment\n\nInitially (on OS X), you will need to setup Brew which is a package manager for OS X and Git. To install Brew and Git, run the following commands:\n\n/usr/bin/ruby -e \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\"\nbrew install git\n\n\nIf you are on Debian/Ubuntu, then you can easily install git with apt-get\n\napt-get update &amp;&amp; apt-get install -y git\n\n\nInstall Jekyll\n\nYou can also install Jekyll with brew.\n\n$ brew install ruby\n$ gem install jekyll\n$ gem install bundler\n$ bundle install\n\n\nOn Ubuntu I do a different method:\n\ngit clone https://github.com/rbenv/ruby-build.git ~/.rbenv/plugins/ruby-build\necho 'export PATH=\"$HOME/.rbenv/plugins/ruby-build/bin:$PATH\"' &gt;&gt; ~/.bashrc\nexec $SHELL\nrbenv install 2.3.1\nrbenv global 2.3.1\ngem install bundler\nrbenv rehash\nruby -v\n\n# Rails\ncurl -sL https://deb.nodesource.com/setup_4.x | sudo -E bash -\nsudo apt-get install -y nodejs\ngem install rails -v 4.2.6\nrbenv rehash\n\n# Jekyll\ngem install jekyll\ngem install github-pages\ngem install jekyll-sass-converter\n\nrbenv rehash\n\n\nGet the code\n\nYou should first fork the repository to your GitHub organization or username,\nand then clone it.\n\n$ git clone https://github.com/&lt;username&lt;/mkdocs-jekyll.git docs\n$ cd docs\n\n\nYou can clone the repository right to where you want to host the docs:\n\n$ git clone https://github.com/&lt;username&gt;/mkdocs-jekyll.git docs\n$ cd docs\n\n\nServe\n\nDepending on how you installed jekyll:\n\njekyll serve\n# or\nbundle exec jekyll serve\n\n\nPreview\n\nWe provide a CircleCI configuration recipe that you\ncan use to preview your site on CircleCI before merging into master. You\nshould follow the instructions to set up a project,\nand then in the project settings be sure to enable building forked build requests,\nand to cancel redundant builds. The preview will be built on CircleCI, and saved\nto static files for you to browse. The only change you will need is to edit\nthe static files location to be the name of your respository, which is at te\nbottom of the .circleci/config.yml file:\n\n      - store_artifacts:\n          path: ~/repo/_site\n          destination: mkdocs-jekyll\n\n\nIn the above, the destination should coincide with your repository name.\nRemember that for most links, CircleCI won’t honor an index.html file in a subfolder\n(e.g., subfolder/index.html will not be served as subfolder/, so for example,\nyou might need to turn this:\n\nhttps://&lt;circleci&gt;/0/mkdocs-jekyll/docs/getting-started/\n\ninto this:\n\nhttps://&lt;circleci&gt;/0/mkdocs-jekyll/docs/getting-started/index.html\n\n\nCustomization\n\nconfig.yml\n\nTo edit configuration values, customize the _config.yml.\nMost are documented there, and please open an issue if you have questions.\n\nAdding pages\n\nTo add pages, write them into the pages folder. \nYou define urls based on the permalink attribute in your pages,\nand then add them to the navigation by adding to the content of _data/toc.yml.\n\nTags\n\nIf you include tags on a page, by default they will link to the tags page on the site. However, if you define a tag_search_endpoint url in your configuration file, by clicking\nthe tag, the user will be taken to this page to search for it. As an example,\nwe define the current search endpoint to be Ask Cyberinfrastructure, and\npage tags link to a search on it:\n\ntag_search_endpoint: https://ask.cyberinfrastructure.org/search?q=\ntag_color: danger # danger, success, warning, primary, secondary, info\n\n\nNote that you can also choose a color! The tags appear at the top of the page,\nas they do on this page. The tags should be defined like this in the front end\nmatter:\n\ntags: \n - jekyll\n - github\n\n\nThey are appended to the first h1 block, so generally your pages should have a header.\nIf you comment out this variable, then each of your tags will link to it’s appropriate\nspot on the tags page linked above.\n\n#tag_search_endpoint: https://ask.cyberinfrastructure.org/search?q=\ntag_color: primary # danger, success, warning, primary, info, secondary"
					}
					
				
		
				
					,
					
					"docs-subfolder-example-page": {
						"id": "docs-subfolder-example-page",
						"title": "A Nested Page",
						"categories": "",
						"url": " /docs/subfolder/example-page",
						"content": "A Nested Page\n\nThis is an example of a page that doesn’t have a permalink defined, and\nis not included in the table of contents (_data/toc.yml)."
					}
					
				
		
		
				
					,
					
					"about": {
						"id": "about",
						"title": "About Me",
						"categories": "",
						"url": " /about/",
						"content": "YuKai Wu\nemail: ywu048@fiu.edu\nEDUCATION\n\n  2009.09—2013.07 AnQing Normal University (bachelor’s degree), major Information and Computing Science\n  2018.05—2019.12 Florida International University, major computer science\n\n\nPROFESSIONAL EXPERIENCE\n\n  \n    2015.9 – 2018.1   HangZhou ShuYun Information Science Corporation (Algorithm Engineer)\n    \n      Design and Development of Recommend System for commodities\nDevelop a framework for Recommendation System, It can train model from users features data and generates a list of recommendation commodities. In this project, My duty is to develop a back-end part that can get data from several recommendation list and merge them by specific algorithm, final push them to user end. I’m also in charge with developing some recommendation algorithms suit for a particular scenario.  This recommendation framework mainly serves the advertising business\n      Design and Development of TaoBao, TMall User Portrait System\nDepend on user shopping records, I establish a label system for each user to represent user feature space. Such as Preference for Clothes, Preference for Cosmetics, Preference for Food  etc. This system can easily group users into several category and improve the precise of recommendation system.\n      Analysis user comment data with NLP\nThe company need extract short label from user comment to help our customer well understand what is the user feeling about their product. I use RNN with attention model to extract the key information in the short comment, and then analyse these data and display the result.\n    \n  \n  \n    2015.6 – 2015.8\t   ShangHai YiChen Information Science Corporation (Big Data Development Engineer)\n    \n      Design and Development of Recommendation System for short videos\n We store user’s history data in Hive, and then we train the Recommendation Models with Spark and store them in HDFS. We develop a frame that automatically deploy the trained models that load from HDFS, and recommend short videos for users, putting the result into Hbase. The frame have RESTful API for responding the request from other front-end programme.\n    \n  \n  \n    2014.5 – 2015.5\t    ANHUI XiangXing Information Science Corporation (Data Mining Engineer)\n    \n      Development of Data Mining System Based on Spark Framework\nThe company want to develop a cloud computing platform for the enterprise to help them analyse huge amount of data. So our task is to integrate Spark into our System, and extend the function and algorithm of MLlib.\n      Data Modeling of Customer Loss with Anhui Telecom User Data\nHelp our customer to build a ML model to predict whether the user would lost or not in the next mouth.  The Telecom company give us lots of user  behavior data without sensitive part.  The label is binary, meaning whether the user would lost in next month.  We use previous four month data to extract the user’s feature, and then input the features into model to predict the user situation in next month.\n    \n  \n\n\nRESEARCH / FIELD WORK EXPERIENCE\n\n  Reinforcement Learning Project:\n    \n      Navigation: Training a agent to learn how to get maximum bananas in one episode,  using the Deep Q-Network(DQN) Algorithm.\n      Reacher: Training a robot arm to quickly catch a target.  In this project, I use the Deep Deterministic Policy Gradient(DDPG) with continuous action space to train 20 virtual agents simultaneously to reduce the training time.\n      Tennis: Two players compete each other. The project is training two agents to play the tennis game and against each other. I learn how to use the DDPG to train multi-agents in competitive environment.\n      Half Field Offense in Robocup 2D Soccer: Training a agent to kick the ball to the goal. This environment action space is parameterized action space. It combine the discrete value and the continuous value.\n    \n  \n  \n    NLP Project:\nWe use four kind of algorithms to complete Name Entity Recognition(NER) task and compare them. (paper)\n  \n  \n    Image Process:\nFor this project, our target is to display the intermediate processes of image-style transformation, how to transform a photo from a original photo to a style photo and what the processes look like. We use VGG19 and transform net (Johnson, J. et al. 2016) to train model for image-style transformation. In each layer of transform net, we use DeconvNet to get visible image from intermediate data to display the changing process. (report)\n  \n  \n    Distributed Framework:\nIt is a distributed system framework and has a master and various pluggable components. The pluggable components can design to divers function components. The master manage all components. The system has a pub-sub system to support communication between all components. The component can publish and subscribe topics. This project based on AKKA concurrency framework with Scala programm language. Here is a Distributed Web Crawler based on this distributed framework,  “crawlnet”.\n  \n  Recommend System:\nThe project target is to design and develop a recommend system to recommend commodity for users.  Our project’s architecture has four part. We use Hive as our data warehouse. It store all the order, user and commodity data. We use Spark to generate modes that used to recommend commodity and store the result into Hbase database. And then we design restful API to receive requests and return the recommendation commodities for users.\n\n\nPROFESSIONAL SKILLS\n\n  Deep learning development skills:\n    \n      Tensorflow, pyTorch and relevant Python lib, Such as Numpy, Pandas etc.\n      Reinforcement learning:\n        \n          Get the Nanodegree in Udacity online course.\n          MDP, DQN, DDPG, PPO, A2C,A3C, .\n        \n      \n      NLP\n        \n          word2vec, RNN, LSTM, seq2seq, and attention model.\n        \n      \n      Image Process\n        \n          CNN, VGG, ResNet, DeconvNet, Image Style_Transfer\n        \n      \n    \n  \n  Big Data development skills:\n    \n      Spark distributed computing system, experience for dealing with large-scale data sets and the spark-mllib machine learning algorithm library.\n      Recommendation System:\n        \n          Framework design and development\n          Design Recommendation Algorithm\n          Design User Portrait\n        \n      \n      AKKA concurrency framework, and Real-time stream processing with Spark.\n      Big Data related systems, such as: Hadoop, Spark, Hive, Hbase, Kafka, Elasticsearch etc.\n      Relational database Mysql and non-relational database, such as : HBase, Mongodb and Redis\n    \n  \n  Development Skills:\n    \n      Programming language Scala, Python, Java, C/C++, SQL, etc.\n      Tools: git, vscode, vs, JetBrains, sbt, Maven, CMake,   Amazon Web Services(AWS)\n    \n  \n\n\nCERTIFICATE\nUdacity Nanodegree:\n\nWEBSITE\nGithub, Linkedin"
					}
					
				
		
				
					,
					
					"archive": {
						"id": "archive",
						"title": "Article",
						"categories": "",
						"url": " /archive/",
						"content": "News Article\n\n2019\n\n\n  May 12, 2019: Function approximation"
					}
					
				
		
				
					,
					
					"docs": {
						"id": "docs",
						"title": "Documentation",
						"categories": "",
						"url": " /docs/",
						"content": "Documentation\n\nWelcome to the Yukai Wu Documentation pages! Here you can quickly jump to a \nparticular page.\n\n\n    \n            \n    \n    A Nested Page\n    An example of a nested page\n            \n    \n    Quiz\n    How to add interactive quizzes to your site.\n            \n    \n    Extras\n    Extras, including quizzes.\n            \n    \n    Getting Started\n    Getting started with Docsy Jekyll\n            \n    \n    A Nested Page\n    An example of a a nested page in a subfolder."
					}
					
				
		
				
					,
					
					"feed-xml": {
						"id": "feed-xml",
						"title": "",
						"categories": "",
						"url": " /feed.xml",
						"content": "Yukai Wu\n    \n    http://localhost:4000/\n    \n    Thu, 09 Jan 2020 21:42:43 -0500\n    Thu, 09 Jan 2020 21:42:43 -0500\n    Jekyll v3.8.5\n    \n      \n        Function approximation\n        &lt;h3 id=&quot;introduce&quot;&gt;Introduce&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;The &lt;strong&gt;policy&lt;/strong&gt;, &lt;strong&gt;value function&lt;/strong&gt; and &lt;strong&gt;model&lt;/strong&gt; are all functions&lt;/li&gt;\n  &lt;li&gt;We want to learn (one of) these from experience&lt;/li&gt;\n  &lt;li&gt;If there are too many states, we need to approximate&lt;/li&gt;\n  &lt;li&gt;In general, this is called RL with function approximation&lt;/li&gt;\n  &lt;li&gt;When using deep neural nets, this is often called deep reinforcement learning&lt;/li&gt;\n  &lt;li&gt;The term is fairly new — the combination is decades old&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;!--more--&gt;\n&lt;h3 id=&quot;value-function-approximation&quot;&gt;Value Function Approximation&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;&lt;strong&gt;lookup tables&lt;/strong&gt;\n    &lt;ul&gt;\n      &lt;li&gt;Every state $s$ has an entry $q(s,a)$&lt;/li&gt;\n      &lt;li&gt;Or every state-action pair $s,a$ has an entry $q(s,a)$&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Large MDPs:\n    &lt;ul&gt;\n      &lt;li&gt;There are too many states and/or actions to store in memory&lt;/li&gt;\n      &lt;li&gt;It is too slow to learn the value of each state individually&lt;/li&gt;\n      &lt;li&gt;Individual states are often &lt;strong&gt;not fully observable&lt;/strong&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Solution for large MDPs:\n    &lt;ul&gt;\n      &lt;li&gt;Estimate value function with &lt;strong&gt;function approximation&lt;/strong&gt;\n &lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[\n\\begin{aligned}\nv_\\theta(s)\\approx v_\\pi(s) \\qquad &amp;(or, v_*(s)) \\\\\nq_\\theta(s,a)\\approx q_\\pi(s,a) \\qquad &amp;(or,q_*(s,a))\n\\end{aligned} %]]&gt;&lt;/script&gt;&lt;/li&gt;\n      &lt;li&gt;&lt;strong&gt;Generalise&lt;/strong&gt; from seen states to unseen states&lt;/li&gt;\n      &lt;li&gt;&lt;strong&gt;Update&lt;/strong&gt; parameter $\\theta$ using MC or TD observable&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;If the environement state is not fully observable:\n    &lt;ul&gt;\n      &lt;li&gt;Use the &lt;strong&gt;agent state&lt;/strong&gt;&lt;/li&gt;\n      &lt;li&gt;Consider learning a &lt;strong&gt;state update function&lt;/strong&gt; $S_{t+1}=u(S_t,O_{t+1})$&lt;/li&gt;\n      &lt;li&gt;Henceforth, $S_t$ denotes the agent state&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;which-function-approximator&quot;&gt;Which Function Approximator?&lt;/h3&gt;\n&lt;p&gt;There are many function approximators, e.g.&lt;/p&gt;\n&lt;ul&gt;\n  &lt;li&gt;Artificial neural network&lt;/li&gt;\n  &lt;li&gt;Decision tree&lt;/li&gt;\n  &lt;li&gt;Nearest neighbour&lt;/li&gt;\n  &lt;li&gt;Fourier / wavelet bases&lt;/li&gt;\n  &lt;li&gt;Coarse coding&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;In principle, &lt;strong&gt;any&lt;/strong&gt; function approximator can be used, but RL has specific properties:&lt;/p&gt;\n&lt;ul&gt;\n  &lt;li&gt;Experience is not i.i.d — successive time-step are correlated&lt;/li&gt;\n  &lt;li&gt;Agent’s policy affects the data it receives&lt;/li&gt;\n  &lt;li&gt;Value functions $v_\\pi(s)$ can be non-stationary&lt;/li&gt;\n  &lt;li&gt;Feedback is delayed, not instantaneous&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;classes-of-function-approximation&quot;&gt;Classes of Function Approximation&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;Tabular: a table with an entry for each MDP state&lt;/li&gt;\n  &lt;li&gt;State aggregation: Partition environment states&lt;/li&gt;\n  &lt;li&gt;Linear function approximate: fixed feature (or fixed kernel)&lt;/li&gt;\n  &lt;li&gt;Differentiable (nonlinear) function approximation: neural nets&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;approximate-values-by-stochastic-gradient-descent&quot;&gt;Approximate Values By Stochastic Gradient Descent&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;Goal: fins $\\theta$ that minimise the difference between $v_\\theta(s)$ and $v_\\pi(s)$ \n&lt;script type=&quot;math/tex&quot;&gt;J(\\theta)=\\mathbb{E}[(v_\\pi(S)-v_\\theta(S))^2]&lt;/script&gt;\n      Note: The expectation if over the state distribution — e.g., induced by the policy&lt;/li&gt;\n  &lt;li&gt;Gradient descent:\n&lt;script type=&quot;math/tex&quot;&gt;\\Delta\\theta=-\\frac{1}{2}\\alpha\\nabla_\\theta J(\\theta)=\\alpha\\mathbb{E}[(v_\\pi(S)-v_\\theta(S))\\nabla_\\theta v_\\theta(S)]&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;Stochastic&lt;/strong&gt; gradient descent\n&lt;script type=&quot;math/tex&quot;&gt;\\Delta\\theta_t=\\alpha(v_\\pi(S_t)-v_\\theta(S_t))\\nabla_\\theta v_\\theta(S_t)&lt;/script&gt;\n    &lt;h3 id=&quot;feature-vectors&quot;&gt;Feature Vectors&lt;/h3&gt;\n    &lt;hr /&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Represent state by a &lt;strong&gt;feature vector&lt;/strong&gt; \n&lt;script type=&quot;math/tex&quot;&gt;\\phi(s) = \\left(\\begin{array}{cc}\n\\phi_1(s) \\\\ \\vdots \\\\ \\phi_n(s)\n\\end{array}\\right)&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;$\\phi:S\\rightarrow\\mathbb{R}^n$ is a fixed mapping from state (e.g. observation) to features&lt;/li&gt;\n  &lt;li&gt;Short-hand: $\\phi_t=\\phi(S_t)$&lt;/li&gt;\n  &lt;li&gt;For example:\n    &lt;ul&gt;\n      &lt;li&gt;Distance of robot from landmarks&lt;/li&gt;\n      &lt;li&gt;Trends in the stock market&lt;/li&gt;\n      &lt;li&gt;Piece and pawn configurations in chess&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;approximate-values-by-stochastic-gradient-descent-1&quot;&gt;Approximate Values By Stochastic Gradient Descent&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;Goal: fina $\\theta$ that minimise the difference between $v_\\theta(s)$ and $v_\\pi(s)$\n&lt;script type=&quot;math/tex&quot;&gt;J(\\theta)=\\mathbb{E}[(v_\\pi(S)-v_\\theta(S))^2]&lt;/script&gt;\n      Note: The expectation if over the state distribution — e.g., induced by the policy.&lt;/li&gt;\n  &lt;li&gt;Gradient desent:\n&lt;script type=&quot;math/tex&quot;&gt;\\Delta\\theta=-\\frac{1}{2}\\alpha\\Delta_\\theta J(\\theta)=\\alpha\\mathbb{E}_\\pi p[(v_\\pi(S)-v_\\theta(S))\\nabla_\\theta v_\\theta(S)]&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;&lt;strong&gt;Stochastic&lt;/strong&gt; gradient descent:\n&lt;script type=&quot;math/tex&quot;&gt;\\Delta\\theta_t=\\alpha(v_\\pi(S_t)-v_\\theta(S_t))\\nabla_\\theta v_\\theta(S_t)&lt;/script&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;linear-value-function-approximation&quot;&gt;Linear Value Function Approximation&lt;/h3&gt;\n&lt;ul&gt;\n  &lt;li&gt;Approximate value function by a linear combination of features\n&lt;script type=&quot;math/tex&quot;&gt;v_\\theta(s)=\\theta^\\top \\phi(s)=\\sum_{j=1}^n\\phi_j(s)\\theta_j&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;Objective function (‘loss’) is quadratic in $\\theta$\n&lt;script type=&quot;math/tex&quot;&gt;J(\\theta)=\\mathbb{E}_\\pi\\big[(v_\\pi(S)-\\theta^\\top\\phi(S))^2\\big]&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;Stichastic gradient descent converges on global ooptimum&lt;/li&gt;\n  &lt;li&gt;Update rule is simple\n&lt;script type=&quot;math/tex&quot;&gt;\\nabla_\\theta v_\\theta(S_t)=\\phi(S_t)=\\phi_t \\quad \\Longrightarrow \\quad \\Delta_\\theta = \\alpha(v_\\pi(S_t)-v_\\theta(S_t))\\phi_t&lt;/script&gt;\n      $\\large \\text{Update}=\\textbf{step size}\\times\\textbf{prediction error}\\times\\textbf{feature vector}$&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;incremental-prediction-algorithms&quot;&gt;Incremental Prediction Algorithms&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;The true value function $v_\\pi(s)$ is typically not available&lt;/li&gt;\n  &lt;li&gt;In practice, we substitute a &lt;strong&gt;target&lt;/strong&gt; for $v_\\pi(s)$\n    &lt;ul&gt;\n      &lt;li&gt;For MC, the target is the return $G_t$\n&lt;script type=&quot;math/tex&quot;&gt;\\Delta\\theta_t=\\alpha(\\textcolor{red}{G_t} - v_\\theta(s))\\nabla_\\theta v_\\theta(s)&lt;/script&gt;&lt;/li&gt;\n      &lt;li&gt;For TD, the target is the TD target $R_{t+1}+\\gamma v_\\theta(S_{t+1})$\n&lt;script type=&quot;math/tex&quot;&gt;\\Delta\\theta_t=\\alpha(\\textcolor{red}{R_{t+1}+\\gamma v_\\theta(S_{t+1})} - v_\\theta(S_t))\\nabla_\\theta v_\\theta(S_t)&lt;/script&gt;&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;monte-carlo-with-value-function-approximation&quot;&gt;Monte-Carlo with Value Function Approximation&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;The return $G_t$ is an unbiased, noisy sample of $v_\\pi(s)$&lt;/li&gt;\n  &lt;li&gt;Can therefore apply supervised learning to (online) “training data”\n&lt;script type=&quot;math/tex&quot;&gt;{(S_0,G_0),\\ldots,(S_t,G_t)}&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;For example, using &lt;strong&gt;linear Monte-Carlo policy evaluation&lt;/strong&gt;\n&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[\n\\begin{aligned}\n\\Delta\\theta_t &amp;=\\alpha(\\textcolor{red}{G_t} - v_\\theta(S_t))\\nabla_\\theta v_\\theta(S_t) \\\\\n&amp; = \\alpha(G_t - v_\\theta(S_t))\\phi_t\n\\end{aligned} %]]&gt;&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;Monte-Carlo evaluation converges to a local optimum&lt;/li&gt;\n  &lt;li&gt;Even when using non-linear value function approximation&lt;/li&gt;\n  &lt;li&gt;For linear function, it finds the globlal optimum&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;td-learning-with-value-function-approximation&quot;&gt;TD Learning with Value Function Approximation&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;The TD-target $R_{t+1}+\\gamma v_\\theta(S_{t+1})$ is a &lt;strong&gt;biased&lt;/strong&gt; sample og true value $v_\\pi(S_t)$&lt;/li&gt;\n  &lt;li&gt;Can still apply supervised learning to “training data”\n&lt;script type=&quot;math/tex&quot;&gt;{(S_0,R_1+\\gamma v_\\theta(S_1)),\\ldots,(S_t,R_{t+1}+\\gamma v_\\theta(S_{t+1}))}&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;For example, using linear TD\n&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[\n\\begin{aligned}\n\\Delta\\theta_t &amp;= \\alpha\\underbrace{(\\textcolor{red}{R_{t+1}+\\gamma v_\\theta(S_{t+1})}-v_\\theta(S_t))}_{\\normalsize =\\delta_t, \\text{TD error}}\\nabla_\\theta v_\\theta(S_t) \\\\\n&amp; =\\alpha\\delta_t\\phi_t\n\\end{aligned} %]]&gt;&lt;/script&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;convergence-of-mc-and-td&quot;&gt;Convergence of MC and TD&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;\n    &lt;p&gt;with linear functions, MC converges to\n&lt;script type=&quot;math/tex&quot;&gt;\\min_\\theta\\mathbb{E}\\big[(G_t-v_\\theta(S_t))^2\\big]=\\mathbb{E}\\big[\\phi_t\\phi_t^\\top\\big]^{-1}\\mathbb{E}\\big[v_\\pi(S_t)\\phi_t\\big]&lt;/script&gt;&lt;/p&gt;\n  &lt;/li&gt;\n  &lt;li&gt;With linear function, TD converges to\n&lt;script type=&quot;math/tex&quot;&gt;\\min_\\theta\\mathbb{E}\\big[(R_{t+1}+\\gamma v_\\theta(S_{t+1}-v_\\theta(S_t)))^2\\big]=\\mathbb{E}\\big[\\phi_t(\\phi_t-\\gamma\\phi_{t+1})^\\top\\big]\\mathbb{E}\\big[R_{t+1}\\phi_t\\big]&lt;/script&gt;\n      (in continuing problem with fixed $\\gamma$)&lt;/li&gt;\n  &lt;li&gt;This is a different solution from MC&lt;/li&gt;\n  &lt;li&gt;Typically, the asymptotic MC solution is preferred&lt;/li&gt;\n  &lt;li&gt;But TD methods may converge faster, and may still be better\n&lt;script type=&quot;math/tex&quot;&gt;\\textbf{TD:}\\quad\\Delta_t=\\alpha\\delta\\nabla_\\theta v_\\theta(S_t)\\quad \\textbf{where} \\quad \\delta_t=R_{t+1}+\\gamma v_\\theta(S_{t+1}-v_\\theta(S_t))&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;This update ignores dependence of $v_\\theta(S_{t+1})$ on $\\theta$&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;action-value-function-approximation&quot;&gt;Action-Value Function Approximation&lt;/h3&gt;\n&lt;ul&gt;\n  &lt;li&gt;Approximate the action-value function\n&lt;script type=&quot;math/tex&quot;&gt;q_\\theta(s,a)\\approx q_\\pi(S,a)&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;For instance, with linear function approximation\n&lt;script type=&quot;math/tex&quot;&gt;q_\\theta(s,a)=\\phi(s,a)_\\top\\theta=\\sum_{j=1}^n\\phi_j(s,a)\\theta_j&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;Stochastic gradient descent update\n&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[\n\\begin{aligned}\n\\Delta\\theta &amp;= \\alpha(q_\\pi(s,a)-q_\\theta(s,a))\\nabla_\\theta q_\\theta(s,a) \\\\\n&amp;= \\alpha(q_\\pi(s,a)-q_\\theta(s,a))\\phi(s,a)\n\\end{aligned} %]]&gt;&lt;/script&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;least-squarse-prediction&quot;&gt;Least Squarse Prediction&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;Given value function approximation $v_\\theta(s) \\approx v_\\pi(s)$&lt;/li&gt;\n  &lt;li&gt;And &lt;strong&gt;experience&lt;/strong&gt; $\\mathcal{D}$ consisting of $\\large \\langle \\text{state, estimated value} \\rangle$pairs\n&lt;script type=&quot;math/tex&quot;&gt;\\mathcal{D}=\\big\\{\\langle S_1,\\hat{v}_1^\\pi \\rangle,\\langle S_2,\\hat{v}_2^\\pi \\rangle,\\ldots,\\langle S_T,\\hat{v}_T^\\pi \\rangle \\big\\}&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;E.g., $\\large \\hat{V}&lt;em&gt;1^\\pi=R&lt;/em&gt;{t+1}+\\gamma v_\\theta(S_{t+1})$&lt;/li&gt;\n  &lt;li&gt;Which parameters $\\theta$ give the best fitting value function $v_\\theta(s)$?&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;stochastic-gradient-descent-with-experience-replay&quot;&gt;Stochastic Gradient Descent with Experience Replay&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;p&gt;Give experience consisting of $\\large \\langle \\text{state, value} \\rangle$pairs\n&lt;script type=&quot;math/tex&quot;&gt;\\mathcal{D}=\\big\\{\\langle S_1,\\hat{v}_1^\\pi \\rangle,\\langle S_2,\\hat{v}_2^\\pi \\rangle,\\ldots,\\langle S_T,\\hat{v}_T^\\pi \\rangle \\big\\}&lt;/script&gt;\nRepeat:&lt;/p&gt;\n&lt;ol&gt;\n  &lt;li&gt;Sample state, value from experience\n&lt;script type=&quot;math/tex&quot;&gt;\\langle s, \\hat{v}_\\pi  \\rangle \\sim \\mathcal{D}&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;Apply stochastic gradient decent update\n&lt;script type=&quot;math/tex&quot;&gt;\\Delta\\theta = \\alpha(\\hat{v}^\\pi - v_\\theta(s))\\nabla_\\theta v_\\theta(s)&lt;/script&gt;\nConverges to least squares solution\n&lt;script type=&quot;math/tex&quot;&gt;\\theta_\\pi=\\mathop{\\text{argmin}}\\limits_\\theta LS(\\theta)=\\mathop{\\text{argmin}}\\limits_\\theta\\mathbb{E}_\\mathcal{D}\\big[(\\hat{v}_i^\\pi-v_\\theta(S_i))^2\\big]&lt;/script&gt;\n    &lt;h3 id=&quot;linear-least-squares-prediction&quot;&gt;Linear Least Squares Prediction&lt;/h3&gt;\n    &lt;hr /&gt;\n    &lt;ul&gt;\n      &lt;li&gt;Experience replay finds least squares solution&lt;/li&gt;\n      &lt;li&gt;But it may take many iterations&lt;/li&gt;\n      &lt;li&gt;Using &lt;strong&gt;linear&lt;/strong&gt; value function approximation $v_\\theta(s)=\\phi(s)^\\top\\theta$ we can solve the least squares solution directly&lt;/li&gt;\n      &lt;li&gt;At minimum of $LS(\\theta)$, the expected update must be zero\n&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[\n\\begin{aligned}\n\\mathbb{E}_\\mathcal{D}[\\Delta\\theta] &amp;= 0 \\\\\n\\alpha\\sum_{t=1}^T\\phi_t(\\hat{v}_t^\\pi-\\phi_t^\\top\\theta) &amp;= 0 \\\\\n\\sum_{t=1}^T\\phi_t\\hat{v}_t^\\pi &amp;= \\sum_{t=1}^T\\phi_t\\phi_t^\\top\\theta \\\\\n\\theta_t &amp;= \\Big(\\sum_{t=1}^T\\phi_t\\phi_t^\\top\\Big)^{-1}\\sum_{t=1}^T\\phi_t\\hat{v}_t^\\pi\n\\end{aligned} %]]&gt;&lt;/script&gt;&lt;/li&gt;\n      &lt;li&gt;For N feature, direct solution time is $O(N^3)$&lt;/li&gt;\n      &lt;li&gt;Incremental solution time is $O(N^2)$ using Shermann-Morrison&lt;/li&gt;\n      &lt;li&gt;We do not know true values $v_\\pi$ (have estimates $\\hat{v}_t$)&lt;/li&gt;\n      &lt;li&gt;In practice, our “training data” must use noisy or biased sample of $v_\\pi$&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;      &amp;lt;font color=blue&amp;gt;&lt;strong&gt;LSMC&lt;/strong&gt;&amp;lt;/font&amp;gt; Least Squares Monte-Carlo uses return\n&lt;script type=&quot;math/tex&quot;&gt;v_\\pi \\approx \\textcolor{red}{G_t}&lt;/script&gt;\n      &amp;lt;font color=blue&amp;gt;&lt;strong&gt;LSTD&lt;/strong&gt;&amp;lt;/font&amp;gt; Least Squares Temporal-Difference uses TD target\n&lt;script type=&quot;math/tex&quot;&gt;v_\\pi \\approx \\textcolor{red}{R_{t+1} + \\gamma v_\\theta(S_{t+1})}&lt;/script&gt;&lt;/p&gt;\n&lt;ul&gt;\n  &lt;li&gt;In each case we can solve directly for the fixed poine&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;deep-reinforcement-learning&quot;&gt;Deep reinforcement learning&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;Many ideas immediately transfer when using deep neural networks:\n    &lt;ul&gt;\n      &lt;li&gt;TD and MC&lt;/li&gt;\n      &lt;li&gt;Double learning (e.g., double Q-learning)&lt;/li&gt;\n      &lt;li&gt;Experience replay&lt;/li&gt;\n      &lt;li&gt;…&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Some ideas do not easily transfer\n    &lt;ul&gt;\n      &lt;li&gt;UCB&lt;/li&gt;\n      &lt;li&gt;Least squares TD/MC&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;neural-q-learning&quot;&gt;Neural Q-learning&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;Online neural Q-learning may include:\n    &lt;ul&gt;\n      &lt;li&gt;A &lt;strong&gt;network&lt;/strong&gt; $q_\\theta:\\medspace O_t \\Longrightarrow (q[1],\\ldots,q[m])(m\\space \\text{actions})$&lt;/li&gt;\n      &lt;li&gt;An $\\epsilon-\\text{greedy}$ &lt;strong&gt;exploration policy&lt;/strong&gt;: $q_t\\medspace \\Longrightarrow \\medspace \\pi_t \\Longrightarrow \\medspace A_t$&lt;/li&gt;\n      &lt;li&gt;A Q-learning &lt;strong&gt;loss function&lt;/strong&gt; on $\\theta$\n&lt;script type=&quot;math/tex&quot;&gt;I(\\theta)=\\frac{1}{2}\\Big(R_{t+1}+\\gamma\\Big[\\max_a q_\\theta (S_{t+1},a)\\Big] - q_\\theta (S_t, A_t)\\Big)^2&lt;/script&gt;\nwhere $[\\cdot ]$ denotes stopping the gradient, so that the gradient is \n&lt;script type=&quot;math/tex&quot;&gt;\\nabla_\\theta I(\\theta)=\\Big(R_{t+1}+\\gamma\\max_a q_\\theta(S_{t+1},a)-q_\\theta(S_t,A_t)\\Big)\\nabla_\\theta q_\\theta(S_t,A_t)&lt;/script&gt;&lt;/li&gt;\n      &lt;li&gt;An &lt;strong&gt;optimizer&lt;/strong&gt; to minimize the loss (e.g., SGD, RMSProp, Adma)&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;dqn&quot;&gt;DQN&lt;/h3&gt;\n&lt;hr /&gt;\n\n&lt;ul&gt;\n  &lt;li&gt;DQN (Mnih et al. 2013, 2015) includes;\n    &lt;ul&gt;\n      &lt;li&gt;A &lt;strong&gt;network&lt;/strong&gt; $q_\\theta:\\medspace O_t \\mapsto (q[1],\\ldots,q[m])(m\\space \\text{actions})$&lt;/li&gt;\n      &lt;li&gt;An $\\epsilon-\\text{greedy}$ &lt;strong&gt;exploration policy&lt;/strong&gt;: $q_t\\medspace \\mapsto \\medspace \\pi_t \\Longrightarrow \\medspace A_t$&lt;/li&gt;\n      &lt;li&gt;A &lt;strong&gt;replay buffer&lt;/strong&gt; to store and sample past transitions&lt;/li&gt;\n      &lt;li&gt;A &lt;strong&gt;target network&lt;/strong&gt; $q_{\\theta^-}:\\medspace Q_t \\mapsto\\space(q^-[1],\\ldots,q^-[m])$&lt;/li&gt;\n      &lt;li&gt;A Q-learning &lt;strong&gt;loss function&lt;/strong&gt; on $\\theta$ (use replay and target network) \n&lt;script type=&quot;math/tex&quot;&gt;I(\\theta)=\\frac{1}{2}\\Big(R_{t+1}+\\gamma\\Big[\\max_a q_{\\theta^-} (S_{t+1},a)\\Big] - q_\\theta (S_t, A_t)\\Big)^2&lt;/script&gt;&lt;/li&gt;\n      &lt;li&gt;An &lt;strong&gt;optimizer&lt;/strong&gt; to minimize the loss (e.g., SGD, RMSProp, Adma)&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Replay and target networks make RL look more like supervised learning&lt;/li&gt;\n  &lt;li&gt;It is unclear whether they are vital, but they help&lt;/li&gt;\n  &lt;li&gt;“DL-aware RL”&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;h3 id=&quot;n-step-return&quot;&gt;n-Step Return&lt;/h3&gt;\n&lt;hr /&gt;\n&lt;ul&gt;\n  &lt;li&gt;\n    &lt;p&gt;Consider the following n-steps returns for $n=1,2,\\infin:$\n&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[\n\\begin{alignedat}a\n&amp;n=1 \\quad &amp;(TD)\\quad &amp; G_T^{(1)}=R_{t+1} + \\gamma v(S_{t+1}) \\\\\n&amp;n=2 \\quad &amp;\\quad &amp; G_T^{(2)}=R_{t+1} + \\gamma R_{t+2} +\\gamma^2 v(S_{t+2}) \\\\\n&amp;\\quad \\vdots \\quad &amp;\\quad &amp; \\vdots \\\\\n&amp;n=\\infin \\quad &amp;(MC)\\quad &amp; G_T^{(\\infin)}=R_{t+1} + \\gamma R_{t+2}+\\ldots+\\gamma^{T-t-1}R_T\n\\end{alignedat} %]]&gt;&lt;/script&gt;&lt;/p&gt;\n  &lt;/li&gt;\n  &lt;li&gt;Define the n-step return\n&lt;script type=&quot;math/tex&quot;&gt;G_t^{(n)} = R_{t+1} + \\gamma R_{t+2} + \\ldots + \\gamma^{n-1} R_{t+n} + \\gamma^n v(S_{t+n})&lt;/script&gt;&lt;/li&gt;\n  &lt;li&gt;n-step temporal-difference learning\n&lt;script type=&quot;math/tex&quot;&gt;v(S_t) \\leftarrow v(S_t) + \\alpha\\Big(G_t^{(n)} - v(S_t)\\Big)&lt;/script&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n        Sun, 12 May 2019 00:00:00 -0400\n        http://localhost:4000/2019/Function-Approximation/\n        http://localhost:4000/2019/Function-Approximation/"
					}
					
				
		
				
					,
					
					"": {
						"id": "",
						"title": "",
						"categories": "",
						"url": " /",
						"content": "Function approximation\n   May 12, 2019\n   \n   Introduce\n\n\n  The policy, value function and model are all functions\n  We want to learn (one of) these from experience\n  If there are too many states, we need to approximate\n  In general, this is called RL with function approximation\n  When using deep neural nets, this is often called deep reinforcement learning\n  The term is fairly new — the combination is decades old\n\n\n\n   \n      read more"
					}
					
				
		
				
		
				
					,
					
					"assets-js-main-js": {
						"id": "assets-js-main-js",
						"title": "",
						"categories": "",
						"url": " /assets/js/main.js",
						"content": "(function($) {\n    'use strict';\n    $(function() {\n        $('[data-toggle=\"tooltip\"]').tooltip();\n        $('[data-toggle=\"popover\"]').popover();\n        $('.popover-dismiss').popover({\n            trigger: 'focus'\n        })\n    });\n\n    function bottomPos(element) {\n        return element.offset().top + element.outerHeight();\n    }\n    $(function() {\n        var promo = $(\".js-td-cover\");\n        if (!promo.length) {\n            return\n        }\n        var promoOffset = bottomPos(promo);\n        var navbarOffset = $('.js-navbar-scroll').offset().top;\n        var threshold = Math.ceil($('.js-navbar-scroll').outerHeight());\n        if ((promoOffset - navbarOffset) < threshold) {\n            $('.js-navbar-scroll').addClass('navbar-bg-onscroll');\n        }\n        $(window).on('scroll', function() {\n            var navtop = $('.js-navbar-scroll').offset().top - $(window).scrollTop();\n            var promoOffset = bottomPos($('.js-td-cover'));\n            var navbarOffset = $('.js-navbar-scroll').offset().top;\n            if ((promoOffset - navbarOffset) < threshold) {\n                $('.js-navbar-scroll').addClass('navbar-bg-onscroll');\n            } else {\n                $('.js-navbar-scroll').removeClass('navbar-bg-onscroll');\n                $('.js-navbar-scroll').addClass('navbar-bg-onscroll--fade');\n            }\n        });\n    });\n}(jQuery));\n(function($) {\n    'use strict';\n    var Search = {\n        init: function() {\n            $(document).ready(function() {\n                $(document).on('keypress', '.td-search-input', function(e) {\n                    if (e.keyCode !== 13) {\n                        return\n                    }\n                    var query = $(this).val();\n                    var searchPage = \"http://localhost:4000/search/?q=\" + query;\n                    document.location = searchPage;\n                    return false;\n                });\n            });\n        },\n    };\n    Search.init();\n}(jQuery));"
					}
					
				
		
				
					,
					
					"news": {
						"id": "news",
						"title": "News",
						"categories": "",
						"url": " /news/",
						"content": "News\n\nSubscribe with RSS to keep up with the latest news.\nFor site changes, see the changelog kept with the code base.\n\n\n\n\n   Function approximation\n   May 12, 2019\n   \n   Introduce\n\n\n  The policy, value function and model are all functions\n  We want to learn (one of) these from experience\n  If there are too many states, we need to approximate\n  In general, this is called RL with function approximation\n  When using deep neural nets, this is often called deep reinforcement learning\n  The term is fairly new — the combination is decades old\n\n\n\n   \n      read more\n   \n   \n\n\nWant to see more? See the News Archive."
					}
					
				
		
				
		
				
		
				
					,
					
					"sitemap-xml": {
						"id": "sitemap-xml",
						"title": "",
						"categories": "",
						"url": " /sitemap.xml",
						"content": "/\n     {{ \"now\" | date: \"%Y-%m-%d\" }}\n     daily\n    \n{% for section in site.data.toc %}\n     {{ site.baseurl }}{{ section.url }}/\n     {{ \"now\" | date: \"%Y-%m-%d\" }}\n     daily\n    \n{% endfor %}"
					}
					
				
		
				
					,
					
					"tags": {
						"id": "tags",
						"title": "Tags Index",
						"categories": "",
						"url": " /tags/",
						"content": "Tags Index\n{% capture site_tags %}{% for tag in site.tags %}{% if tag %}{{ tag | first }}{% unless forloop.last %},{% endunless %}{% endif %}{% endfor %}{% endcapture %}{% assign docs_tags = \"\" %}{% for doc in site.docs %}{% assign ttags = doc.tags | join:',' | append:',' %}{% assign docs_tags = docs_tags | append:ttags %}{% endfor %}\n{% assign all_tags = site_tags | append:docs_tags %}{% assign tags_list = all_tags | split:',' | uniq | sort %}\n\n{% for tag in tags_list %}{% if tag %}{{ tag }}\n\n    {% for post in site.tags[tag] %}\n    {{- post.title -}}\n     {{- post.date | date: \"%B %d, %Y\" -}}\n{%- endfor -%}\n{% for doc in site.docs %}{% if doc.tags contains tag %}\n\n    {{ doc.title }}\n         {{- doc.date | date: \"%B %d, %Y\" -}}\n    {% endif %}{% endfor %}\n{% endif %}{%- endfor -%}"
					}
					
				
		
				
					,
					
					"assets-css-style-css": {
						"id": "assets-css-style-css",
						"title": "",
						"categories": "",
						"url": " /assets/css/style.css",
						"content": "@import \"jekyll-theme-primer\";"
					}
					
				
		
	};
</script>
<script src="/assets/js/lunr.min.js"></script>
<script src="/assets/js/search.js"></script>

<script
  src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>

<script>
$(document).ready(function() {

    var toc = $('#TOC');

    // Select each header
    sections = $('.td-content h1');
        $.each(sections, function(idx, v) {
            section = $(v);
            var div_id = $(section).attr('id');
            var div_text = section.text().split('¶')[0];
            var parent = $("#" + div_id)
            var content = '<li id="link_' + div_id + '" class="md-nav__item"><a class="md-nav__link" href="#' + div_id + '" title="' + div_text +'">' + div_text +'</a></li>';
            $(toc).append(content);

            // Add section code to subnavigation
            var children = $('<nav class="md-nav"><ul class="md-nav__list"></nav></ul>')
            var contenders = $("#" + div_id).nextUntil("h1");
            $.each(contenders, function(idx, contender){
               if($(contender).is('h2') || $(contender).is('h3')) {
                   var contender_id = $(contender).attr('id');
                   var contender_text = $(contender).text().split('¶')[0];
                   var content = '<li class="md-nav__item"><a class="md-nav__link" href="#' + contender_id + '" title="' + contender_text +'">' + contender_text +'</a></li>';
                   children.append(content);
                }
             })
             $("#link_" + div_id).append(children);
        });
    });
</script>

<script>
var headers = ["h1", "h2", "h3", "h4"]
var colors = ["red", "orange", "green", "blue"]

$.each(headers, function(i, header){
    var color = colors[i];
    $(header).each(function () {
        var href=$(this).attr("id");
        $(this).append('<a class="headerlink" style="color:' + color + '" href="#' + href + '" title="Permanent link">¶</a>')
    });
})
</script>



	
              
              <!-- <style>
  .feedback--answer {
    display: inline-block;
  }
  .feedback--answer-no {
    margin-left: 1em;
  }
  .feedback--response {
    display: none;
    margin-top: 1em;
  }
  .feedback--response__visible {
    display: block;
  }
</style>
<h5 class="feedback--title">Feedback</h5>
<p class="feedback--question">Was this page helpful?</p>
<button class="feedback--answer feedback--answer-yes">Yes</button>
<button class="feedback--answer feedback--answer-no">No</button>
<p class="feedback--response feedback--response-yes">
  Glad to hear it! Please <a href="/issues/new">tell us how we can improve</a>.
</p>
<p class="feedback--response feedback--response-no">
  Sorry to hear that. Please <a href="/issues/new">tell us how we can improve</a>.
</p>
<script>
  const yesButton = document.querySelector('.feedback--answer-yes');
  const noButton = document.querySelector('.feedback--answer-no');
  const yesResponse = document.querySelector('.feedback--response-yes');
  const noResponse = document.querySelector('.feedback--response-no');
  const disableButtons = () => {
    yesButton.disabled = true;
    noButton.disabled = true;
  };
  const sendFeedback = (value) => {
    if (typeof ga !== 'function') return;
    const args = {
      command: 'send',
      hitType: 'event',
      category: 'Helpful',
      action: 'click',
      label: window.location.pathname,
      value: value
    };
    ga(args.command, args.hitType, args.category, args.action, args.label, args.value);
  };
  yesButton.addEventListener('click', () => {
    yesResponse.classList.add('feedback--response__visible');
    disableButtons();
    sendFeedback(1);
  });
  noButton.addEventListener('click', () => {
    noResponse.classList.add('feedback--response__visible');
    disableButtons();
    sendFeedback(0);
  });
</script><br/>

 -->
           </div>
          </main>
        </div>
      </div>
      <footer class="bg-dark py-5 row d-print-none">
  <div class="container-fluid mx-sm-5">
    <div class="row">
      <div class="col-6 col-sm-4 text-xs-center order-sm-2">
        

</div>
<div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">  
  <li class="list-inline-item mx-2 h3" data-toggle="tooltip" data-placement="top" title="" aria-label="GitHub" data-original-title="GitHub">
    <a class="text-white" target="_blank" href="">
      <i class="fab fa-github"></i>
    </a>
  </li>
</ul>
</div>
<div class="col-12 col-sm-4 text-center py-2 order-sm-2">
  <small class="text-white">© 2019 Yukai Wu All Rights Reserved</small>
  
  <p class="mt-2"><a href="/about/">About Docsy</a></p>	
      </div>
    </div>
  </div>
</footer>

    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js" integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy" crossorigin="anonymous"></script>
<script src="/assets/js/main.js"></script>

  </body>
</html>
